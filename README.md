
# ğŸ“˜ Proyecto Procesamiento de ReseÃ±as de Trustpilot mediante Scraping Web

Este proyecto implementa un flujo completo de **extracciÃ³n, limpieza, transformaciÃ³n y visualizaciÃ³n** de reseÃ±as obtenidas desde la plataforma **Trustpilot**. La soluciÃ³n combina scraping automatizado, procesamiento estructurado y un dashboard interactivo orientado al anÃ¡lisis de la experiencia del cliente.

Incluye:  
- ğŸ•¸ï¸ **Web Scraping** automatizado con Selenium  
- ğŸ§¹ **ETL** (limpieza, validaciÃ³n y normalizaciÃ³n de datos)  
- ğŸ—‚ï¸ **Datalake estructurado** con tres zonas  
- ğŸ“Š **Dashboard interactivo en Streamlit**  
- ğŸ¤– **AnÃ¡lisis de sentimiento** usando modelos BERT en espaÃ±ol  
- ğŸ” **VisualizaciÃ³n de tendencias, nubes de palabras y distribuciÃ³n de calificaciones**

---

## ğŸ“ Estructura del proyecto (Datalake)

````
datalake/
â”‚
â”œâ”€â”€ 1_LANDING_ZONE/         # Datos crudos obtenidos por scraping
â”œâ”€â”€ 2_REFINED_ZONE/         # Datos limpios y transformados (JSON final)
â””â”€â”€ 3_CONSUMPTION_ZONE/     # Dashboard Streamlit listo para ejecuciÃ³n
````


---

## ğŸ§© Requisitos del sistema

- **Linux Debian** o similar  
- **Python 3.13.0**  
- **Google Chrome**  
- **Jupyter Notebook**  
- **VS Code** (opcional)

---

## âš™ï¸ InstalaciÃ³n de librerÃ­as

Ejecutar en terminal:

```bash
pip install pandas selenium plotly streamlit sqlalchemy psycopg2-binary webdriver-manager jupyter nltk pytz transformers wordcloud

```
Instalar stopwords (solo primera vez):

```bash
python -c "import nltk; nltk.download('stopwords')"
```

---

## ğŸš€ EjecuciÃ³n del proyecto

### 1ï¸âƒ£ Ejecutar el cuaderno ETL

Desde Jupyter o VS Code:

```bash
jupyter notebook scrapp.ipynb
```

Este cuaderno realiza:

* ExtracciÃ³n de reseÃ±as mediante scraping
* Limpieza, validaciÃ³n y estandarizaciÃ³n de datos
* ConversiÃ³n de fechas y normalizaciÃ³n de textos
* GeneraciÃ³n del archivo final:

```
datalake/2_REFINED_ZONE/dataset_reviews_limpio.json
```

---

### 2ï¸âƒ£ Ejecutar el dashboard

Desde la raÃ­z del proyecto:

```bash
streamlit run datalake/3_CONSUMPTION_ZONE/app.py
```

### Funcionalidades del dashboard:

* Filtro por categorÃ­a, empresa, aÃ±o y mes
* Nube de palabras dinÃ¡mica
* AnÃ¡lisis de sentimiento automÃ¡tico
* DistribuciÃ³n de calificaciones por empresa
* Actividad diaria de reseÃ±as
* Tabla detallada de reseÃ±as
* KPI de volumen, promedio de calificaciÃ³n y sentimiento



